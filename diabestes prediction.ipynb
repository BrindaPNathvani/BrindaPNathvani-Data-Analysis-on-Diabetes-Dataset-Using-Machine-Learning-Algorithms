{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RtEp6EdV4rhq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightgbm\n",
            "  Using cached lightgbm-4.3.0.tar.gz (1.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightgbm) (1.26.2)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightgbm) (1.11.4)\n",
            "Building wheels for collected packages: lightgbm\n",
            "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for lightgbm \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[42 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:44,882 - scikit_build_core - INFO - RUN: /Users/brindanathvani/opt/anaconda3/bin/cmake --version\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:44,965 - scikit_build_core - INFO - CMake version: 3.28.1\n",
            "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.8.2\u001b[0m using \u001b[94mCMake 3.28.1\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:44,969 - scikit_build_core - INFO - Build directory: /private/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build\n",
            "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:45,054 - scikit_build_core - INFO - RUN: /private/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/pip-build-env-nedbmhq9/normal/lib/python3.10/site-packages/ninja/data/bin/ninja --version\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:45,277 - scikit_build_core - INFO - Ninja version: 1.11.1\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:45,278 - scikit_build_core - WARNING - libdir/ldlibrary: /Library/Frameworks/Python.framework/Versions/3.10/lib/Python.framework/Versions/3.10/Python is not a real file!\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:45,280 - scikit_build_core - INFO - RUN: /Users/brindanathvani/opt/anaconda3/bin/cmake -S. -B/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build -DCMAKE_BUILD_TYPE:STRING=Release -C/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build/CMakeInit.txt -DCMAKE_MAKE_PROGRAM=/private/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/pip-build-env-nedbmhq9/normal/lib/python3.10/site-packages/ninja/data/bin/ninja -D__BUILD_FOR_PYTHON:BOOL=ON\n",
            "  \u001b[31m   \u001b[0m loading initial cache file /var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build/CMakeInit.txt\n",
            "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 15.0.0.15000309\n",
            "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 15.0.0.15000309\n",
            "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
            "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
            "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
            "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
            "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
            "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
            "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
            "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
            "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
            "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
            "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n",
            "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n",
            "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n",
            "  \u001b[31m   \u001b[0m -- Found OpenMP_C: -Xpreprocessor -fopenmp -I/include\n",
            "  \u001b[31m   \u001b[0m -- Found OpenMP_CXX: -Xpreprocessor -fopenmp -I/include\n",
            "  \u001b[31m   \u001b[0m -- Found OpenMP: TRUE\n",
            "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH\n",
            "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH - Success\n",
            "  \u001b[31m   \u001b[0m -- Using _mm_prefetch\n",
            "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC\n",
            "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC - Success\n",
            "  \u001b[31m   \u001b[0m -- Using _mm_malloc\n",
            "  \u001b[31m   \u001b[0m -- Configuring done (5.4s)\n",
            "  \u001b[31m   \u001b[0m -- Generating done (0.0s)\n",
            "  \u001b[31m   \u001b[0m -- Build files have been written to: /var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build\n",
            "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mBuilding project with \u001b[94mNinja\u001b[0m...\u001b[0m\n",
            "  \u001b[31m   \u001b[0m 2024-03-11 16:45:50,882 - scikit_build_core - INFO - RUN: /Users/brindanathvani/opt/anaconda3/bin/cmake --build /var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/tmpj2e3p7d8/build\n",
            "  \u001b[31m   \u001b[0m ninja: error: '/lib/libomp.dylib', needed by '/private/var/folders/8q/dlkc1p2d4t33kdmvpq725wmm0000gn/T/pip-install-lmuwbfps/lightgbm_332d2469e1744e43a77766661d1d5e82/lib_lightgbm.so', missing and no known rule to make it\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m \u001b[91m\u001b[1m*** CMake build failed\u001b[0m\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build lightgbm\n",
            "\u001b[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
            "    for line in lines:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
            "    for segment in segments:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
            "    renderable = rich_cast(renderable)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
            "    renderable = cast_method()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
            "    pip_cmd = get_best_invocation_for_this_pip()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
            "    if found_executable and os.path.samefile(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
            "    s2 = os.stat(f2)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
            "Call stack:\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
            "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
            "    self.handleError(record)\n",
            "Message: '[present-rich] %s'\n",
            "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
          ]
        }
      ],
      "source": [
        "#! pip install seaborn\n",
        "#! pip install imblearn\n",
        "#! pip install xgboost\n",
        "#! pip install catboost\n",
        "# Install virtualenv if you haven't already\n",
        "#! pip install lightgbm\n",
        "\n",
        "! pip3 install lightgbm\n",
        "\n",
        "\n",
        "\n",
        "#! pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttJw1_Kf4hP1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lightgbm'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool, cv\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, cross_val_score\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,accuracy_score, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier, Pool, cv\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7O9RWDtF4hTp",
        "outputId": "0b5fb2a1-a502-4a26-b1ea-bfa07fa80665"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"diabetes_prediction_dataset.csv\")\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.info()\n",
        "\n",
        "df.describe().transpose()\n",
        "\n",
        "\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "id": "6oA1a4w44hWh",
        "outputId": "86457fe7-298f-4795-cd46-10165bf1dac5"
      },
      "outputs": [],
      "source": [
        "#Check for null values in the dataset\n",
        "df.isnull().sum()\n",
        "\n",
        "#Checking the number of unique values\n",
        "df.select_dtypes(include='int64').nunique()\n",
        "\n",
        "\n",
        "#check duplicate values\n",
        "df.duplicated().sum()\n",
        "\n",
        "#drop the duplicated values\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df.shape\n",
        "\n",
        "column_names = df.columns.tolist()\n",
        "print(\"Column Names:\")\n",
        "print(column_names)\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=['int64'])\n",
        "numeric_columns.hist(bins=20, figsize=(15, 10))\n",
        "plt.show()\n",
        "\n",
        "# Combined side-by-side count plot for categorical variables\n",
        "categorical_columns = ['blood_glucose_level','smoking_history',]\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(categorical_columns), figsize=(14, 5))\n",
        "\n",
        "for i, col in enumerate(categorical_columns):\n",
        "    sns.countplot(x=col, data=df, ax=axes[i], palette='pastel')\n",
        "    axes[i].set_title(f'Count Plot of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "dDZdLiO04hbS",
        "outputId": "ed02d760-2345-44aa-f147-1549155d208c"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Stacked Area Chart .\n",
        "crosstab = pd.crosstab(df['age'],df['blood_glucose_level'])\n",
        "crosstab.plot(kind='area', colormap='viridis', alpha=0.7, stacked=True)\n",
        "plt.title('Stacked Area Chart: Age Category by Blood_glucose_level')\n",
        "plt.xlabel('Age Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "#Stacked Area Chart .\n",
        "crosstab = pd.crosstab(df['age'],df['diabetes'])\n",
        "crosstab.plot(kind='area', colormap='viridis', alpha=0.7, stacked=True)\n",
        "plt.title('Stacked Area Chart: Age Category by General Health')\n",
        "plt.xlabel('Age Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0r6cjGNq4he0",
        "outputId": "b8a674d1-4d3f-486b-a6bd-a6884d73ccbf"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the DataFrame to avoid modifying the original\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Create a label encoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through each object column and encode its values\n",
        "for column in df_encoded.select_dtypes(include='object'):\n",
        "    df_encoded[column] = label_encoder.fit_transform(df_encoded[column])\n",
        "\n",
        "# Now, df_encoded contains the label-encoded categorical columns\n",
        "df_encoded.head()\n",
        "\n",
        "#Correlation Heatmap\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(df_encoded.corr(), fmt='.2g', annot=True)\n",
        "\n",
        "#CHECK THE CLASS VARIABLE\n",
        "df_encoded['diabetes'].value_counts()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df_encoded.drop(columns=['diabetes'])  # Features\n",
        "y = df_encoded['diabetes']  # Target variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_q2QykBw5Xzj",
        "outputId": "a2a23467-fec5-4005-b270-76b09b064d8a"
      },
      "outputs": [],
      "source": [
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the new splits\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define the columns to remove outliers\n",
        "selected_columns = ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "\n",
        "# Calculate the IQR for the selected columns in the training data\n",
        "Q1 = X_train[selected_columns].quantile(0.25)\n",
        "Q3 = X_train[selected_columns].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# SetTING a threshold value for outlier detection (e.g., 1.5 times the IQR)\n",
        "threshold = 1.5\n",
        "\n",
        "# CreatING a mask for outliers in the selected columns\n",
        "outlier_mask = (\n",
        "    (X_train[selected_columns] < (Q1 - threshold * IQR)) |\n",
        "    (X_train[selected_columns] > (Q3 + threshold * IQR))\n",
        ").any(axis=1)\n",
        "\n",
        "# Remove rows with outliers from X_train and y_train\n",
        "X_train_clean = X_train[~outlier_mask]\n",
        "y_train_clean = y_train[~outlier_mask]\n",
        "\n",
        "# Print the number of rows removed\n",
        "num_rows_removed = len(X_train) - len(X_train_clean)\n",
        "print(f\"Number of rows removed due to outliers: {num_rows_removed}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fiB_WnRR5Xwe",
        "outputId": "af4d7763-28b3-4e0b-b777-dbcdd2306b35"
      },
      "outputs": [],
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Make predictions on the test set\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, lr_predictions)\n",
        "mae = mean_absolute_error(y_test, lr_predictions)\n",
        "print(f\"Linear Regression Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Linear Regression Mean Absolute Error: {mae:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DXRFeK9k5Xt3",
        "outputId": "1f58f94f-1d7b-46fb-e97f-67f1ca34af5c"
      },
      "outputs": [],
      "source": [
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Make predictions on the test set\n",
        "logistic_predictions = logistic_model.predict(X_test)\n",
        "\n",
        "# Calculate AUC\n",
        "logistic_auc = roc_auc_score(y_test, logistic_predictions)\n",
        "\n",
        "# Generate ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, logistic_predictions)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, logistic_predictions)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logistic_predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3bDeF_685Xqv",
        "outputId": "2c84fe3a-883e-4320-fbd8-8cf9cedbee4c"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline with the KNN classifier\n",
        "knn_pipeline = make_pipeline(KNeighborsClassifier())\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'kneighborsclassifier__n_neighbors': [3, 5, 7],  # You can add more values to test\n",
        "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Predict on the test set using the best estimator\n",
        "y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4trs_nml5Xnv",
        "outputId": "34ed74b9-6c5b-40dc-84d7-efa8edc8ea72"
      },
      "outputs": [],
      "source": [
        "# Best Parameters for Decision Tree Classifier\n",
        "best_params = {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
        "\n",
        "# Create and train the Decision Tree Classifier with the specified parameters\n",
        "dt_classifier = DecisionTreeClassifier(criterion=best_params['criterion'],\n",
        "                                       max_depth=best_params['max_depth'],\n",
        "                                       min_samples_leaf=best_params['min_samples_leaf'],\n",
        "                                       min_samples_split=best_params['min_samples_split'],\n",
        "                                       random_state=0)\n",
        "\n",
        "dt_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "report_dt = classification_report(y_test, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Model Accuracy:\", accuracy_dt)\n",
        "print(\"Decision Tree Classification Report:\\n\", report_dt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jK7uUMDo5Xjw",
        "outputId": "33d4cf7f-c47d-4c74-e502-ed55338bff4e"
      },
      "outputs": [],
      "source": [
        "# Create and train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=0, max_features='sqrt', n_estimators=100, max_depth=10)\n",
        "rf_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OLLhYeWt5Xgw",
        "outputId": "e6507444-0384-472f-be33-7d5c81fb741d"
      },
      "outputs": [],
      "source": [
        "# Create and train the XGBoost Classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42,max_features='sqrt', n_estimators=100, max_depth=10)\n",
        "xgb_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"XGBoost Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jZ4Cio3F6Feh",
        "outputId": "f1a0f527-c2e9-487d-825e-b3bb199528d5"
      },
      "outputs": [],
      "source": [
        "# Create the CatBoost Classifier\n",
        "catboost_classifier = CatBoostClassifier(random_seed=42, logging_level='Silent', learning_rate=0.1, depth=10,subsample=0.8)\n",
        "\n",
        "catboost_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = catboost_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"CatBoost Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ELqs4Ubc6Fbv",
        "outputId": "af77112b-dd34-4c1c-e162-fbd038fbca3d"
      },
      "outputs": [],
      "source": [
        "# Create the Gradient Boosting Classifier\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42, verbose=0, learning_rate=0.1,subsample=0.8)\n",
        "\n",
        "gb_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Gradient Boosting Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TkfM27YS6FYi",
        "outputId": "fe649b75-f214-4e52-8d33-60234d4c02d7"
      },
      "outputs": [],
      "source": [
        "# Create the LightGBM Classifier\n",
        "lgb_classifier = LGBMClassifier(random_state=42)\n",
        "\n",
        "lgb_classifier.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"LightGBM Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "DBaBx1pb6FVH",
        "outputId": "f4300e13-4e43-4cd6-e408-1cae043c445f"
      },
      "outputs": [],
      "source": [
        "# Define a list of classifiers and their names excluding Linear Regression\n",
        "classifiers = [logistic_model, best_estimator, dt_classifier, rf_classifier, xgb_classifier, catboost_classifier, gb_classifier, lgb_classifier]\n",
        "classifier_names = [\"Logistic Regression\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"XGBoost\", \"CatBoost\", \"Gradient Boosting\", \"LightGBM\"]\n",
        "\n",
        "# Create a function to plot ROC curve and calculate AUC\n",
        "def plot_roc_curve_and_auc(classifiers, classifier_names, X_test, y_test):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for classifier, name in zip(classifiers, classifier_names):\n",
        "        if hasattr(classifier, 'predict_proba'):  # Check if the classifier has predict_proba method\n",
        "            y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            try:\n",
        "                y_pred_prob = classifier.decision_function(X_test)\n",
        "            except AttributeError:\n",
        "                raise AttributeError(f\"{name} does not have predict_proba or decision_function method.\")\n",
        "\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "        auc = roc_auc_score(y_test, y_pred_prob)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f}\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC curves and calculate AUC for classifiers excluding Linear Regression\n",
        "plot_roc_curve_and_auc(classifiers, classifier_names, X_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ixWIb8DH6V_M",
        "outputId": "b60f4c24-8cc7-4b22-832e-4a1c80943254"
      },
      "outputs": [],
      "source": [
        "# Create the CatBoost Classifier\n",
        "catboost_classifier = CatBoostClassifier(random_seed=42, logging_level='Silent', learning_rate=0.1, depth=10, subsample=0.8)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "cv_scores = cross_val_score(catboost_classifier, X_train_clean, y_train_clean, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", cv_scores.mean())\n",
        "\n",
        "\n",
        "# Select a random sample of 10 rows\n",
        "random_sample = df_encoded.sample(n=25, random_state=42)\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X_sample = random_sample.drop(\"diabetes\", axis=1)\n",
        "y_sample = random_sample[\"diabetes\"]\n",
        "\n",
        "# Load the best CatBoost model with the identified parameters\n",
        "best_catboost_model = CatBoostClassifier(random_seed=42, logging_level='Silent', learning_rate=0.1, depth=10, subsample=0.8)\n",
        "\n",
        "# Fit the model to the entire training data using the best parameters\n",
        "best_catboost_model.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predict on the random sample\n",
        "y_pred_sample = best_catboost_model.predict(X_sample)\n",
        "\n",
        "# Display the predictions\n",
        "predictions_df = pd.DataFrame({\"Actual\": y_sample, \"Predicted\": y_pred_sample})\n",
        "print(predictions_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RwWawJt36V7o",
        "outputId": "c3d38c4b-9518-41d0-e74f-16cd0b9571cb"
      },
      "outputs": [],
      "source": [
        "# Neural Network Model with TensorFlow/Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Assuming the data is already preprocessed and split into X_train, X_test, y_train, y_test\n",
        "\n",
        "# Standardize the data (if not already done)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save('diabetes_prediction_neural_network_model.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
